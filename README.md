## introduction and flow
Automatic machine learning (AutoML) has gained wide attention and applications in both industry and academia. Automatic hyper-parameter optimization(auto-HPO) is one of the most critical parts. The effectiveness of many machine learning algorithms is extremely sensitive to hyper-parameters. Without a good set of hyper-parameters, the task cannot be solved well even with the optimal algorithm.

Our contributions are summarized as follows.
- We consider the mapping from data to the optimal hyper-parameters and apply this mapping to the selection of the optimal hyper-parameters. On different tasks of an algorithm, the model has strong transferability, which greatly saves time overhead. For this reason, the model can achieve ultra-high-dimensional optimization of hyper-parameters.

- With XGBoost as an example, we design the neural network structure for the mapping as well as training approaches, which could be applied to other machine learning tasks with slight modification.

\item Experimental results on real data demonstrate that the proposed approach significantly outperforms the state-of-art algorithms in both accuracy and efficiency.
In the remaining of this paper,  Section~\ref{sec:method} describes the proposed approach. Experiments are conducted in Section~\ref{sec:exp}. We overview related work in Section~\ref{sec:related}. Section~\ref{sec:con} draws the conclusions.


## operation method

## experiment

### data set

### baseline

### result

